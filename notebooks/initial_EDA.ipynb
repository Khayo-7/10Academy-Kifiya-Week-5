{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importib import reload\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 16:33:40 - INFO - Failed to load SSL library: <class 'OSError'> (no library called \"ssl\" found)\n",
      "2025-01-17 16:33:40 - INFO - Failed to load SSL library: <class 'OSError'> (no library called \"ssl\" found)\n",
      "2025-01-17 16:33:40 - INFO - Failed to load SSL library: <class 'OSError'> (no library called \"ssl\" found)\n",
      "2025-01-17 16:33:40 - INFO - cryptg module not installed and libssl not found, falling back to (slower) Python encryption\n",
      "2025-01-17 16:33:40 - INFO - cryptg module not installed and libssl not found, falling back to (slower) Python encryption\n",
      "2025-01-17 16:33:40 - INFO - cryptg module not installed and libssl not found, falling back to (slower) Python encryption\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicSegmenter.py:55: SyntaxWarning: invalid escape sequence '\\s'\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicSegmenter.py:79: SyntaxWarning: invalid escape sequence '\\s'\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicSegmenter.py:55: SyntaxWarning: invalid escape sequence '\\s'\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicSegmenter.py:79: SyntaxWarning: invalid escape sequence '\\s'\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicNormalizer.py:87: SyntaxWarning: invalid escape sequence '\\s'\n",
      "c:\\Users\\Darkles\\10academy\\env\\Lib\\site-packages\\amseg-2.3-py3.12.egg\\amseg\\amharicNormalizer.py:87: SyntaxWarning: invalid escape sequence '\\s'\n",
      "2025-01-17 16:33:53 - INFO - PyTorch version 2.5.1 available.\n",
      "2025-01-17 16:33:53 - INFO - PyTorch version 2.5.1 available.\n",
      "2025-01-17 16:33:53 - INFO - PyTorch version 2.5.1 available.\n",
      "2025-01-17 16:33:53 - INFO - PyTorch version 2.5.1 available.\n",
      "2025-01-17 16:33:53 - INFO - PyTorch version 2.5.1 available.\n",
      "2025-01-17 16:33:53 - INFO - TensorFlow version 2.18.0 available.\n",
      "2025-01-17 16:33:53 - INFO - TensorFlow version 2.18.0 available.\n",
      "2025-01-17 16:33:53 - INFO - TensorFlow version 2.18.0 available.\n",
      "2025-01-17 16:33:53 - INFO - TensorFlow version 2.18.0 available.\n",
      "2025-01-17 16:33:53 - INFO - TensorFlow version 2.18.0 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scripts.data_utils.loaders import *\n",
    "from scripts.data_utils.cleaning import *\n",
    "from scripts.data_utils.extract import *\n",
    "from scripts.data_utils.scraper import *\n",
    "from scripts.data_utils.label_data import *\n",
    "from scripts.data_utils.tokenizer import *\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHANNELS = [\n",
    "    \"ZemenExpress\", \"nevacomputer\", \"meneshayeofficial\", \"ethio_brand_collection\", \"Leyueqa\",\n",
    "    \"sinayelj\", \"Shewabrand\", \"helloomarketethiopia\", \"modernshoppingcenter\", \"qnashcom\",\n",
    "    \"Fashiontera\", \"kuruwear\", \"gebeyaadama\", \"MerttEka\", \"forfreemarket\", \"classybrands\",\n",
    "    \"marakibrand\", \"aradabrand2\", \"marakisat2\", \"belaclassic\", \"AwasMart\", \"qnashcom\"\n",
    "]\n",
    "\n",
    "# Run only for selected channels\n",
    "LIMIT = 500\n",
    "output_dir=os.path.join(OUTPUT_DIR, \"messages_with_media.csv\")\n",
    "run_fetch_process(channels=CHANNELS[10:15], limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"resources/data/raw/shageronlinestore_messages.csv\"\n",
    "    OUTPUT_FILE = \"resources/data/processed/preprocessed_messages.csv\"\n",
    "    preprocess_data(INPUT_FILE, OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Removed emojis and special characters from the text.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n",
      "2025-01-17 16:34:37 - INFO - Normalized Amharic text by removing diacritics.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'·àÜ·ã®·àÜ·â§·àÜ·âµ·àÜ ·àÜ·ãç·àÜ·àµ·àÜ·å•·àÜ ·àÜ·ä•·àÜ·âÉ·àÜ·ãé·àÜ·âΩ·àÜ ·àÜ·â†·àÜ1·àÜ0·àÜ0·àÜ0·àÜ ·àÜ·â•·àÜ·à≠·àÜ ·àÜ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"·ã®·â§·âµ ·ãç·àµ·å• ·ä•·âÉ·ãé·âΩ ·â†1000 ·â•·à≠! üõí\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n",
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n",
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n",
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n",
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n",
      "2025-01-17 16:34:19 - INFO - Tokenizing the text.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['·àÜ·ã®·àÜ·â§·àÜ·âµ·àÜ', '·àÜ·ãç·àÜ·àµ·àÜ·å•·àÜ', '·àÜ·ä•·àÜ·âÉ·àÜ·ãé·àÜ·âΩ·àÜ', '·àÜ·â†·àÜ1·àÜ0·àÜ0·àÜ0·àÜ', '·àÜ·â•·àÜ·à≠·àÜ', '·àÜ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(cleaned_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n",
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n",
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n",
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n",
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n",
      "2025-01-17 16:34:42 - INFO - Extracted text from image: ..\\resources\\data\\photos\\@Shageronlinestore_3.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = os.path.join('..', 'resources', 'data', 'photos')\n",
    "img_file = os.path.join(image_dir, '@Shageronlinestore_3.jpg')\n",
    "\n",
    "image_text = extract_text_from_image(img_file)\n",
    "image_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv()\n",
    "cleaned_df = clean_data(df)\n",
    "cleaned_df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_birr_path = 'labeled_telegram_product_price_location.txt'\n",
    "save_labeled_data_to_file(cleaned_df, labeled_data_birr_path, 'Labeled_Message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_csv(cleaned_data_path)\n",
    "    labeled_data = label_data(data, 'cleaned_text')\n",
    "    \n",
    "    # Save labeled data in CoNLL format\n",
    "    save_to_conll(labeled_data, os.path.join(label_dir, 'labeled_data.conll'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_df = read_and_process_lines(labeled_data_birr_path)\n",
    "tokens, labels = separate_tokens_and_labels(labeled_df.values.tolist())\n",
    "tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = initialize_tokenizer(model_name)\n",
    "aligned_tokens, aligned_labels = tokenize_and_align_labels(tokenizer, tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 20 results\n",
    "for token, label in zip(aligned_tokens[:20], aligned_labels[:20]):\n",
    "    print(f\"{token:20} {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Amharic segmenter\n",
    "sent_punct, word_punct = [], []\n",
    "segmenter = AmharicSegmenter(sent_punct, word_punct)\n",
    "new_tokens, new_labels = tokenize_and_align_labels(segmenter, tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first 20 aligned tokens and labels\n",
    "for token, label in zip(new_tokens[:20], new_labels[:20]):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final tokens and labels to a CSV file\n",
    "save_to_csv(new_tokens, new_labels, 'tokens_labels_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(data, \"preprocessed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
